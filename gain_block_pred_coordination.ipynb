{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383fa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Configure which GPU\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from utils.NN_utils import BeamPredictionModel, BlockPredictionModel, BestGainPredictionModel\n",
    "from utils.NN_utils import BeamPredictionLSTMModel, BlockPredictionLSTMModel, BestGainPredictionLSTMModel\n",
    "from utils.NN_utils import preprocess_data\n",
    "from utils.options import args_parser\n",
    "from utils.mox_utils import setup_seed, get_save_dirs, np2torch, save_NN_results\n",
    "from utils.data_utils import get_prepared_dataset, prepare_dataset\n",
    "from utils.beam_utils import generate_dft_codebook, beamIdPair_to_beamPairId, beamPairId_to_beamIdPair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650f79e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BeamPredictionModel:\n\tMissing key(s) in state_dict: \"shared_layers.0.fc1.weight\", \"shared_layers.0.bn1.weight\", \"shared_layers.0.bn1.bias\", \"shared_layers.0.bn1.running_mean\", \"shared_layers.0.bn1.running_var\", \"shared_layers.0.fc2.weight\", \"shared_layers.0.bn2.weight\", \"shared_layers.0.bn2.bias\", \"shared_layers.0.bn2.running_mean\", \"shared_layers.0.bn2.running_var\", \"shared_layers.0.downsample.0.weight\", \"shared_layers.0.downsample.1.weight\", \"shared_layers.0.downsample.1.bias\", \"shared_layers.0.downsample.1.running_mean\", \"shared_layers.0.downsample.1.running_var\", \"shared_layers.2.fc1.weight\", \"shared_layers.2.bn1.weight\", \"shared_layers.2.bn1.bias\", \"shared_layers.2.bn1.running_mean\", \"shared_layers.2.bn1.running_var\", \"shared_layers.2.fc2.weight\", \"shared_layers.2.bn2.weight\", \"shared_layers.2.bn2.bias\", \"shared_layers.2.bn2.running_mean\", \"shared_layers.2.bn2.running_var\", \"shared_layers.2.downsample.0.weight\", \"shared_layers.2.downsample.1.weight\", \"shared_layers.2.downsample.1.bias\", \"shared_layers.2.downsample.1.running_mean\", \"shared_layers.2.downsample.1.running_var\", \"shared_layers.4.fc1.weight\", \"shared_layers.4.bn1.weight\", \"shared_layers.4.bn1.bias\", \"shared_layers.4.bn1.running_mean\", \"shared_layers.4.bn1.running_var\", \"shared_layers.4.fc2.weight\", \"shared_layers.4.bn2.weight\", \"shared_layers.4.bn2.bias\", \"shared_layers.4.bn2.running_mean\", \"shared_layers.4.bn2.running_var\", \"shared_layers.4.downsample.0.weight\", \"shared_layers.4.downsample.1.weight\", \"shared_layers.4.downsample.1.bias\", \"shared_layers.4.downsample.1.running_mean\", \"shared_layers.4.downsample.1.running_var\", \"shared_layers.6.fc1.weight\", \"shared_layers.6.bn1.weight\", \"shared_layers.6.bn1.bias\", \"shared_layers.6.bn1.running_mean\", \"shared_layers.6.bn1.running_var\", \"shared_layers.6.fc2.weight\", \"shared_layers.6.bn2.weight\", \"shared_layers.6.bn2.bias\", \"shared_layers.6.bn2.running_mean\", \"shared_layers.6.bn2.running_var\", \"shared_layers.6.downsample.0.weight\", \"shared_layers.6.downsample.1.weight\", \"shared_layers.6.downsample.1.bias\", \"shared_layers.6.downsample.1.running_mean\", \"shared_layers.6.downsample.1.running_var\", \"shared_layers.8.fc1.weight\", \"shared_layers.8.bn1.weight\", \"shared_layers.8.bn1.bias\", \"shared_layers.8.bn1.running_mean\", \"shared_layers.8.bn1.running_var\", \"shared_layers.8.fc2.weight\", \"shared_layers.8.bn2.weight\", \"shared_layers.8.bn2.bias\", \"shared_layers.8.bn2.running_mean\", \"shared_layers.8.bn2.running_var\", \"shared_layers.8.downsample.0.weight\", \"shared_layers.8.downsample.1.weight\", \"shared_layers.8.downsample.1.bias\", \"shared_layers.8.downsample.1.running_mean\", \"shared_layers.8.downsample.1.running_var\", \"output_heads.0.2.downsample.0.weight\", \"output_heads.0.2.downsample.1.weight\", \"output_heads.0.2.downsample.1.bias\", \"output_heads.0.2.downsample.1.running_mean\", \"output_heads.0.2.downsample.1.running_var\", \"output_heads.1.2.downsample.0.weight\", \"output_heads.1.2.downsample.1.weight\", \"output_heads.1.2.downsample.1.bias\", \"output_heads.1.2.downsample.1.running_mean\", \"output_heads.1.2.downsample.1.running_var\", \"output_heads.2.2.downsample.0.weight\", \"output_heads.2.2.downsample.1.weight\", \"output_heads.2.2.downsample.1.bias\", \"output_heads.2.2.downsample.1.running_mean\", \"output_heads.2.2.downsample.1.running_var\", \"output_heads.3.2.downsample.0.weight\", \"output_heads.3.2.downsample.1.weight\", \"output_heads.3.2.downsample.1.bias\", \"output_heads.3.2.downsample.1.running_mean\", \"output_heads.3.2.downsample.1.running_var\". \n\tUnexpected key(s) in state_dict: \"lstm_layers.weight_ih_l0\", \"lstm_layers.weight_hh_l0\", \"lstm_layers.bias_ih_l0\", \"lstm_layers.bias_hh_l0\", \"output_heads.0.4.fc1.weight\", \"output_heads.0.4.bn1.weight\", \"output_heads.0.4.bn1.bias\", \"output_heads.0.4.bn1.running_mean\", \"output_heads.0.4.bn1.running_var\", \"output_heads.0.4.bn1.num_batches_tracked\", \"output_heads.0.4.fc2.weight\", \"output_heads.0.4.bn2.weight\", \"output_heads.0.4.bn2.bias\", \"output_heads.0.4.bn2.running_mean\", \"output_heads.0.4.bn2.running_var\", \"output_heads.0.4.bn2.num_batches_tracked\", \"output_heads.0.6.fc1.weight\", \"output_heads.0.6.bn1.weight\", \"output_heads.0.6.bn1.bias\", \"output_heads.0.6.bn1.running_mean\", \"output_heads.0.6.bn1.running_var\", \"output_heads.0.6.bn1.num_batches_tracked\", \"output_heads.0.6.fc2.weight\", \"output_heads.0.6.bn2.weight\", \"output_heads.0.6.bn2.bias\", \"output_heads.0.6.bn2.running_mean\", \"output_heads.0.6.bn2.running_var\", \"output_heads.0.6.bn2.num_batches_tracked\", \"output_heads.0.6.downsample.0.weight\", \"output_heads.0.6.downsample.1.weight\", \"output_heads.0.6.downsample.1.bias\", \"output_heads.0.6.downsample.1.running_mean\", \"output_heads.0.6.downsample.1.running_var\", \"output_heads.0.6.downsample.1.num_batches_tracked\", \"output_heads.1.4.fc1.weight\", \"output_heads.1.4.bn1.weight\", \"output_heads.1.4.bn1.bias\", \"output_heads.1.4.bn1.running_mean\", \"output_heads.1.4.bn1.running_var\", \"output_heads.1.4.bn1.num_batches_tracked\", \"output_heads.1.4.fc2.weight\", \"output_heads.1.4.bn2.weight\", \"output_heads.1.4.bn2.bias\", \"output_heads.1.4.bn2.running_mean\", \"output_heads.1.4.bn2.running_var\", \"output_heads.1.4.bn2.num_batches_tracked\", \"output_heads.1.6.fc1.weight\", \"output_heads.1.6.bn1.weight\", \"output_heads.1.6.bn1.bias\", \"output_heads.1.6.bn1.running_mean\", \"output_heads.1.6.bn1.running_var\", \"output_heads.1.6.bn1.num_batches_tracked\", \"output_heads.1.6.fc2.weight\", \"output_heads.1.6.bn2.weight\", \"output_heads.1.6.bn2.bias\", \"output_heads.1.6.bn2.running_mean\", \"output_heads.1.6.bn2.running_var\", \"output_heads.1.6.bn2.num_batches_tracked\", \"output_heads.1.6.downsample.0.weight\", \"output_heads.1.6.downsample.1.weight\", \"output_heads.1.6.downsample.1.bias\", \"output_heads.1.6.downsample.1.running_mean\", \"output_heads.1.6.downsample.1.running_var\", \"output_heads.1.6.downsample.1.num_batches_tracked\", \"output_heads.2.4.fc1.weight\", \"output_heads.2.4.bn1.weight\", \"output_heads.2.4.bn1.bias\", \"output_heads.2.4.bn1.running_mean\", \"output_heads.2.4.bn1.running_var\", \"output_heads.2.4.bn1.num_batches_tracked\", \"output_heads.2.4.fc2.weight\", \"output_heads.2.4.bn2.weight\", \"output_heads.2.4.bn2.bias\", \"output_heads.2.4.bn2.running_mean\", \"output_heads.2.4.bn2.running_var\", \"output_heads.2.4.bn2.num_batches_tracked\", \"output_heads.2.6.fc1.weight\", \"output_heads.2.6.bn1.weight\", \"output_heads.2.6.bn1.bias\", \"output_heads.2.6.bn1.running_mean\", \"output_heads.2.6.bn1.running_var\", \"output_heads.2.6.bn1.num_batches_tracked\", \"output_heads.2.6.fc2.weight\", \"output_heads.2.6.bn2.weight\", \"output_heads.2.6.bn2.bias\", \"output_heads.2.6.bn2.running_mean\", \"output_heads.2.6.bn2.running_var\", \"output_heads.2.6.bn2.num_batches_tracked\", \"output_heads.2.6.downsample.0.weight\", \"output_heads.2.6.downsample.1.weight\", \"output_heads.2.6.downsample.1.bias\", \"output_heads.2.6.downsample.1.running_mean\", \"output_heads.2.6.downsample.1.running_var\", \"output_heads.2.6.downsample.1.num_batches_tracked\", \"output_heads.3.4.fc1.weight\", \"output_heads.3.4.bn1.weight\", \"output_heads.3.4.bn1.bias\", \"output_heads.3.4.bn1.running_mean\", \"output_heads.3.4.bn1.running_var\", \"output_heads.3.4.bn1.num_batches_tracked\", \"output_heads.3.4.fc2.weight\", \"output_heads.3.4.bn2.weight\", \"output_heads.3.4.bn2.bias\", \"output_heads.3.4.bn2.running_mean\", \"output_heads.3.4.bn2.running_var\", \"output_heads.3.4.bn2.num_batches_tracked\", \"output_heads.3.6.fc1.weight\", \"output_heads.3.6.bn1.weight\", \"output_heads.3.6.bn1.bias\", \"output_heads.3.6.bn1.running_mean\", \"output_heads.3.6.bn1.running_var\", \"output_heads.3.6.bn1.num_batches_tracked\", \"output_heads.3.6.fc2.weight\", \"output_heads.3.6.bn2.weight\", \"output_heads.3.6.bn2.bias\", \"output_heads.3.6.bn2.running_mean\", \"output_heads.3.6.bn2.running_var\", \"output_heads.3.6.bn2.num_batches_tracked\", \"output_heads.3.6.downsample.0.weight\", \"output_heads.3.6.downsample.1.weight\", \"output_heads.3.6.downsample.1.bias\", \"output_heads.3.6.downsample.1.running_mean\", \"output_heads.3.6.downsample.1.running_var\", \"output_heads.3.6.downsample.1.num_batches_tracked\". \n\tsize mismatch for output_heads.0.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.0.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.0.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.1.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.2.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.3.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.3.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m block_pred_model \u001b[38;5;241m=\u001b[39m BlockPredictionModel(feature_input_dim, num_bs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m gain_pred_model \u001b[38;5;241m=\u001b[39m BestGainPredictionModel(feature_input_dim, num_bs)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mbeam_pred_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/beampred_lstm_valAcc93.01\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m_2025-04-29_20:55:34.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m block_pred_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/blockpred_lstm_valAcc98.87\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_2025-04-26_13:08:55.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m gain_pred_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/gainpred_lstm_valMae2.06dB_2025-04-29_20:18:49.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/sionna/lib/python3.10/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BeamPredictionModel:\n\tMissing key(s) in state_dict: \"shared_layers.0.fc1.weight\", \"shared_layers.0.bn1.weight\", \"shared_layers.0.bn1.bias\", \"shared_layers.0.bn1.running_mean\", \"shared_layers.0.bn1.running_var\", \"shared_layers.0.fc2.weight\", \"shared_layers.0.bn2.weight\", \"shared_layers.0.bn2.bias\", \"shared_layers.0.bn2.running_mean\", \"shared_layers.0.bn2.running_var\", \"shared_layers.0.downsample.0.weight\", \"shared_layers.0.downsample.1.weight\", \"shared_layers.0.downsample.1.bias\", \"shared_layers.0.downsample.1.running_mean\", \"shared_layers.0.downsample.1.running_var\", \"shared_layers.2.fc1.weight\", \"shared_layers.2.bn1.weight\", \"shared_layers.2.bn1.bias\", \"shared_layers.2.bn1.running_mean\", \"shared_layers.2.bn1.running_var\", \"shared_layers.2.fc2.weight\", \"shared_layers.2.bn2.weight\", \"shared_layers.2.bn2.bias\", \"shared_layers.2.bn2.running_mean\", \"shared_layers.2.bn2.running_var\", \"shared_layers.2.downsample.0.weight\", \"shared_layers.2.downsample.1.weight\", \"shared_layers.2.downsample.1.bias\", \"shared_layers.2.downsample.1.running_mean\", \"shared_layers.2.downsample.1.running_var\", \"shared_layers.4.fc1.weight\", \"shared_layers.4.bn1.weight\", \"shared_layers.4.bn1.bias\", \"shared_layers.4.bn1.running_mean\", \"shared_layers.4.bn1.running_var\", \"shared_layers.4.fc2.weight\", \"shared_layers.4.bn2.weight\", \"shared_layers.4.bn2.bias\", \"shared_layers.4.bn2.running_mean\", \"shared_layers.4.bn2.running_var\", \"shared_layers.4.downsample.0.weight\", \"shared_layers.4.downsample.1.weight\", \"shared_layers.4.downsample.1.bias\", \"shared_layers.4.downsample.1.running_mean\", \"shared_layers.4.downsample.1.running_var\", \"shared_layers.6.fc1.weight\", \"shared_layers.6.bn1.weight\", \"shared_layers.6.bn1.bias\", \"shared_layers.6.bn1.running_mean\", \"shared_layers.6.bn1.running_var\", \"shared_layers.6.fc2.weight\", \"shared_layers.6.bn2.weight\", \"shared_layers.6.bn2.bias\", \"shared_layers.6.bn2.running_mean\", \"shared_layers.6.bn2.running_var\", \"shared_layers.6.downsample.0.weight\", \"shared_layers.6.downsample.1.weight\", \"shared_layers.6.downsample.1.bias\", \"shared_layers.6.downsample.1.running_mean\", \"shared_layers.6.downsample.1.running_var\", \"shared_layers.8.fc1.weight\", \"shared_layers.8.bn1.weight\", \"shared_layers.8.bn1.bias\", \"shared_layers.8.bn1.running_mean\", \"shared_layers.8.bn1.running_var\", \"shared_layers.8.fc2.weight\", \"shared_layers.8.bn2.weight\", \"shared_layers.8.bn2.bias\", \"shared_layers.8.bn2.running_mean\", \"shared_layers.8.bn2.running_var\", \"shared_layers.8.downsample.0.weight\", \"shared_layers.8.downsample.1.weight\", \"shared_layers.8.downsample.1.bias\", \"shared_layers.8.downsample.1.running_mean\", \"shared_layers.8.downsample.1.running_var\", \"output_heads.0.2.downsample.0.weight\", \"output_heads.0.2.downsample.1.weight\", \"output_heads.0.2.downsample.1.bias\", \"output_heads.0.2.downsample.1.running_mean\", \"output_heads.0.2.downsample.1.running_var\", \"output_heads.1.2.downsample.0.weight\", \"output_heads.1.2.downsample.1.weight\", \"output_heads.1.2.downsample.1.bias\", \"output_heads.1.2.downsample.1.running_mean\", \"output_heads.1.2.downsample.1.running_var\", \"output_heads.2.2.downsample.0.weight\", \"output_heads.2.2.downsample.1.weight\", \"output_heads.2.2.downsample.1.bias\", \"output_heads.2.2.downsample.1.running_mean\", \"output_heads.2.2.downsample.1.running_var\", \"output_heads.3.2.downsample.0.weight\", \"output_heads.3.2.downsample.1.weight\", \"output_heads.3.2.downsample.1.bias\", \"output_heads.3.2.downsample.1.running_mean\", \"output_heads.3.2.downsample.1.running_var\". \n\tUnexpected key(s) in state_dict: \"lstm_layers.weight_ih_l0\", \"lstm_layers.weight_hh_l0\", \"lstm_layers.bias_ih_l0\", \"lstm_layers.bias_hh_l0\", \"output_heads.0.4.fc1.weight\", \"output_heads.0.4.bn1.weight\", \"output_heads.0.4.bn1.bias\", \"output_heads.0.4.bn1.running_mean\", \"output_heads.0.4.bn1.running_var\", \"output_heads.0.4.bn1.num_batches_tracked\", \"output_heads.0.4.fc2.weight\", \"output_heads.0.4.bn2.weight\", \"output_heads.0.4.bn2.bias\", \"output_heads.0.4.bn2.running_mean\", \"output_heads.0.4.bn2.running_var\", \"output_heads.0.4.bn2.num_batches_tracked\", \"output_heads.0.6.fc1.weight\", \"output_heads.0.6.bn1.weight\", \"output_heads.0.6.bn1.bias\", \"output_heads.0.6.bn1.running_mean\", \"output_heads.0.6.bn1.running_var\", \"output_heads.0.6.bn1.num_batches_tracked\", \"output_heads.0.6.fc2.weight\", \"output_heads.0.6.bn2.weight\", \"output_heads.0.6.bn2.bias\", \"output_heads.0.6.bn2.running_mean\", \"output_heads.0.6.bn2.running_var\", \"output_heads.0.6.bn2.num_batches_tracked\", \"output_heads.0.6.downsample.0.weight\", \"output_heads.0.6.downsample.1.weight\", \"output_heads.0.6.downsample.1.bias\", \"output_heads.0.6.downsample.1.running_mean\", \"output_heads.0.6.downsample.1.running_var\", \"output_heads.0.6.downsample.1.num_batches_tracked\", \"output_heads.1.4.fc1.weight\", \"output_heads.1.4.bn1.weight\", \"output_heads.1.4.bn1.bias\", \"output_heads.1.4.bn1.running_mean\", \"output_heads.1.4.bn1.running_var\", \"output_heads.1.4.bn1.num_batches_tracked\", \"output_heads.1.4.fc2.weight\", \"output_heads.1.4.bn2.weight\", \"output_heads.1.4.bn2.bias\", \"output_heads.1.4.bn2.running_mean\", \"output_heads.1.4.bn2.running_var\", \"output_heads.1.4.bn2.num_batches_tracked\", \"output_heads.1.6.fc1.weight\", \"output_heads.1.6.bn1.weight\", \"output_heads.1.6.bn1.bias\", \"output_heads.1.6.bn1.running_mean\", \"output_heads.1.6.bn1.running_var\", \"output_heads.1.6.bn1.num_batches_tracked\", \"output_heads.1.6.fc2.weight\", \"output_heads.1.6.bn2.weight\", \"output_heads.1.6.bn2.bias\", \"output_heads.1.6.bn2.running_mean\", \"output_heads.1.6.bn2.running_var\", \"output_heads.1.6.bn2.num_batches_tracked\", \"output_heads.1.6.downsample.0.weight\", \"output_heads.1.6.downsample.1.weight\", \"output_heads.1.6.downsample.1.bias\", \"output_heads.1.6.downsample.1.running_mean\", \"output_heads.1.6.downsample.1.running_var\", \"output_heads.1.6.downsample.1.num_batches_tracked\", \"output_heads.2.4.fc1.weight\", \"output_heads.2.4.bn1.weight\", \"output_heads.2.4.bn1.bias\", \"output_heads.2.4.bn1.running_mean\", \"output_heads.2.4.bn1.running_var\", \"output_heads.2.4.bn1.num_batches_tracked\", \"output_heads.2.4.fc2.weight\", \"output_heads.2.4.bn2.weight\", \"output_heads.2.4.bn2.bias\", \"output_heads.2.4.bn2.running_mean\", \"output_heads.2.4.bn2.running_var\", \"output_heads.2.4.bn2.num_batches_tracked\", \"output_heads.2.6.fc1.weight\", \"output_heads.2.6.bn1.weight\", \"output_heads.2.6.bn1.bias\", \"output_heads.2.6.bn1.running_mean\", \"output_heads.2.6.bn1.running_var\", \"output_heads.2.6.bn1.num_batches_tracked\", \"output_heads.2.6.fc2.weight\", \"output_heads.2.6.bn2.weight\", \"output_heads.2.6.bn2.bias\", \"output_heads.2.6.bn2.running_mean\", \"output_heads.2.6.bn2.running_var\", \"output_heads.2.6.bn2.num_batches_tracked\", \"output_heads.2.6.downsample.0.weight\", \"output_heads.2.6.downsample.1.weight\", \"output_heads.2.6.downsample.1.bias\", \"output_heads.2.6.downsample.1.running_mean\", \"output_heads.2.6.downsample.1.running_var\", \"output_heads.2.6.downsample.1.num_batches_tracked\", \"output_heads.3.4.fc1.weight\", \"output_heads.3.4.bn1.weight\", \"output_heads.3.4.bn1.bias\", \"output_heads.3.4.bn1.running_mean\", \"output_heads.3.4.bn1.running_var\", \"output_heads.3.4.bn1.num_batches_tracked\", \"output_heads.3.4.fc2.weight\", \"output_heads.3.4.bn2.weight\", \"output_heads.3.4.bn2.bias\", \"output_heads.3.4.bn2.running_mean\", \"output_heads.3.4.bn2.running_var\", \"output_heads.3.4.bn2.num_batches_tracked\", \"output_heads.3.6.fc1.weight\", \"output_heads.3.6.bn1.weight\", \"output_heads.3.6.bn1.bias\", \"output_heads.3.6.bn1.running_mean\", \"output_heads.3.6.bn1.running_var\", \"output_heads.3.6.bn1.num_batches_tracked\", \"output_heads.3.6.fc2.weight\", \"output_heads.3.6.bn2.weight\", \"output_heads.3.6.bn2.bias\", \"output_heads.3.6.bn2.running_mean\", \"output_heads.3.6.bn2.running_var\", \"output_heads.3.6.bn2.num_batches_tracked\", \"output_heads.3.6.downsample.0.weight\", \"output_heads.3.6.downsample.1.weight\", \"output_heads.3.6.downsample.1.bias\", \"output_heads.3.6.downsample.1.running_mean\", \"output_heads.3.6.downsample.1.running_var\", \"output_heads.3.6.downsample.1.num_batches_tracked\". \n\tsize mismatch for output_heads.0.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.0.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.0.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.0.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.1.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.1.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.1.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.2.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.2.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.2.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for output_heads.3.2.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for output_heads.3.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for output_heads.3.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512])."
     ]
    }
   ],
   "source": [
    "setup_seed(20)\n",
    "freq = 28e9\n",
    "DS_start, DS_end = 800, 950\n",
    "preprocess_mode = 2\n",
    "pos_in_data = preprocess_mode==2\n",
    "look_ahead_len = 10\n",
    "n_pilot = 16\n",
    "M_r, N_bs, M_t = 8, 4, 64\n",
    "P_t = 1e-1\n",
    "P_noise = 1e-14 # -174dBm/Hz * 1.8MHz = 7.165929069962946e-15 W\n",
    "gpu = 4\n",
    "device = f'cuda:{gpu}' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "\n",
    "prepared_dataset_filename, data_np, veh_h_np, veh_pos_np, best_beam_pair_index_np \\\n",
    "    = get_prepared_dataset(preprocess_mode, DS_start, DS_end, M_t, M_r, freq, n_pilot, N_bs, P_t, P_noise, look_ahead_len)\n",
    "data_torch = np2torch(data_np[:,0,...],device) \n",
    "veh_h_torch = np2torch(veh_h_np[:,-1,...],device) \n",
    "veh_pos_torch = np2torch(veh_pos_np[:,-1,...],device) \n",
    "best_beam_pair_index_torch = np2torch(best_beam_pair_index_np[:,-1,...],device)\n",
    "block_labels = (veh_h_torch[:,0,:,0]==0).long().to(device)\n",
    "DFT_tx = generate_dft_codebook(M_t)\n",
    "DFT_rx = generate_dft_codebook(M_r)\n",
    "beamPairId = best_beam_pair_index_torch.detach().cpu().numpy()\n",
    "beamIdPair = beamPairId_to_beamIdPair(beamPairId,M_t,M_r)\n",
    "num_car, _, num_bs, _ = veh_h_torch.shape\n",
    "channel = veh_h_torch.detach().cpu().numpy()\n",
    "g_opt = np.zeros((num_car,num_bs)).astype(np.float32)\n",
    "for veh in range(num_car):\n",
    "    for bs in range(num_bs):\n",
    "        g_opt[veh,bs] = 1/np.sqrt(M_t*M_r)*np.abs(np.matmul(np.matmul(channel[veh,:,bs,:], DFT_tx[:,beamIdPair[veh,bs,0]]).T.conjugate(),DFT_rx[:,beamIdPair[veh,bs,1]]))\n",
    "        g_opt[veh,bs] = 20 * np.log10(g_opt[veh,bs] + 1e-9) \n",
    "g_opt_normalized = g_opt / 20 + 7\n",
    "gain_labels = torch.tensor(g_opt_normalized).to(device)\n",
    "\n",
    "feature_input_dim = data_torch.shape[-1] * 2 - pos_in_data * 2\n",
    "num_bs = 4\n",
    "num_beampair = M_t * M_r\n",
    "\n",
    "beam_pred_model = BeamPredictionModel(feature_input_dim, num_bs, num_beampair).to(device)\n",
    "block_pred_model = BlockPredictionModel(feature_input_dim, num_bs).to(device)\n",
    "gain_pred_model = BestGainPredictionModel(feature_input_dim, num_bs).to(device)\n",
    "\n",
    "beam_pred_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/beampred_lstm_valAcc93.01%_2025-04-29_20:55:34.pth'))\n",
    "block_pred_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/blockpred_lstm_valAcc98.87%_2025-04-26_13:08:55.pth'))\n",
    "gain_pred_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/gainpred_lstm_valMae2.06dB_2025-04-29_20:18:49.pth'))\n",
    "\n",
    "data = preprocess_data(data_torch, pos_in_data)\n",
    "beam_pred_model.eval()\n",
    "block_pred_model.eval()\n",
    "gain_pred_model.eval()\n",
    "with torch.no_grad():\n",
    "    beam_pred = beam_pred_model(data).argmax(dim=-1)\n",
    "    block_pred = block_pred_model(data).argmax(dim=-1)\n",
    "    gain_pred = gain_pred_model.pred(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954444ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeamPredictionModel(\n",
       "  (shared_layers): Sequential(\n",
       "    (0): VectorResBlock(\n",
       "      (fc1): Linear(in_features=258, out_features=128, bias=False)\n",
       "      (bn1): BatchNorm1d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Linear(in_features=258, out_features=128, bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ReLU()\n",
       "    (2): VectorResBlock(\n",
       "      (fc1): Linear(in_features=128, out_features=64, bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=64, bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): ReLU()\n",
       "    (4): VectorResBlock(\n",
       "      (fc1): Linear(in_features=64, out_features=32, bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Linear(in_features=32, out_features=32, bias=False)\n",
       "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=False)\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): ReLU()\n",
       "    (6): VectorResBlock(\n",
       "      (fc1): Linear(in_features=32, out_features=64, bias=False)\n",
       "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=64, bias=False)\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): ReLU()\n",
       "    (8): VectorResBlock(\n",
       "      (fc1): Linear(in_features=64, out_features=128, bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=128, bias=False)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (output_heads): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=False)\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_pred_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32492943",
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_pred == block_labels).to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs((gain_pred.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ebd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_pred.max(), gain_pred.min(), g_opt.max(), g_opt.min() #  -69.123604~-148.2894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535187f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain_pred and block_pred coordination\n",
    "np.abs(((gain_pred*(1-block_pred) - 180.*block_pred).detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip gain_pred\n",
    "gain_pred_clipLB = gain_pred*(gain_pred>=-180.) - 180.*(gain_pred<-180.)\n",
    "np.abs((gain_pred_clipLB.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7c62b",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44e464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BestGainPredictionLSTMModel(\n",
       "  (lstm_layers): LSTM(258, 128, batch_first=True)\n",
       "  (shared_layers): Sequential()\n",
       "  (output_heads): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ReLU()\n",
       "      (2): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ReLU()\n",
       "      (4): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): ReLU()\n",
       "      (6): VectorResBlock(\n",
       "        (fc1): Linear(in_features=128, out_features=1, bias=False)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Linear(in_features=1, out_features=1, bias=False)\n",
       "        (bn2): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=1, bias=False)\n",
       "          (1): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_seed(20)\n",
    "freq = 28e9\n",
    "DS_start, DS_end = 800, 950\n",
    "preprocess_mode = 2\n",
    "pos_in_data = preprocess_mode==2\n",
    "look_ahead_len = 10\n",
    "n_pilot = 16\n",
    "M_r, N_bs, M_t = 8, 4, 64\n",
    "P_t = 1e-1\n",
    "P_noise = 1e-14 # -174dBm/Hz * 1.8MHz = 7.165929069962946e-15 W\n",
    "gpu = 3\n",
    "device = f'cuda:{gpu}' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using device: ', device)\n",
    "\n",
    "prepared_dataset_filename, data_np, veh_h_np, veh_pos_np, best_beam_pair_index_np \\\n",
    "    = get_prepared_dataset(preprocess_mode, DS_start, DS_end, M_t, M_r, freq, n_pilot, N_bs, P_t, P_noise, look_ahead_len)\n",
    "data_torch = np2torch(data_np[:,:-1,...],device) \n",
    "veh_h_torch = np2torch(veh_h_np[:,-1,...],device) \n",
    "veh_pos_torch = np2torch(veh_pos_np[:,-1,...],device) \n",
    "best_beam_pair_index_torch = np2torch(best_beam_pair_index_np[:,-1,...],device)\n",
    "block_labels = (veh_h_torch[:,0,:,0]==0).long().to(device)\n",
    "DFT_tx = generate_dft_codebook(M_t)\n",
    "DFT_rx = generate_dft_codebook(M_r)\n",
    "beamPairId = best_beam_pair_index_torch.detach().cpu().numpy()\n",
    "beamIdPair = beamPairId_to_beamIdPair(beamPairId,M_t,M_r)\n",
    "num_car, _, num_bs, _ = veh_h_torch.shape\n",
    "channel = veh_h_torch.detach().cpu().numpy()\n",
    "g_opt = np.zeros((num_car,num_bs)).astype(np.float32)\n",
    "for veh in range(num_car):\n",
    "    for bs in range(num_bs):\n",
    "        g_opt[veh,bs] = 1/np.sqrt(M_t*M_r)*np.abs(np.matmul(np.matmul(channel[veh,:,bs,:], DFT_tx[:,beamIdPair[veh,bs,0]]).T.conjugate(),DFT_rx[:,beamIdPair[veh,bs,1]]))\n",
    "        g_opt[veh,bs] = 20 * np.log10(g_opt[veh,bs] + 1e-9) \n",
    "g_opt_normalized = g_opt / 20 + 7\n",
    "gain_labels = torch.tensor(g_opt_normalized).to(device)\n",
    "\n",
    "feature_input_dim = data_torch.shape[-1] * 2 - pos_in_data * 2\n",
    "num_bs = 4\n",
    "num_beampair = M_t * M_r\n",
    "\n",
    "beam_pred_lstm_model = BeamPredictionLSTMModel(feature_input_dim, num_bs, num_beampair).to(device)\n",
    "block_pred_lstm_model = BlockPredictionLSTMModel(feature_input_dim, num_bs).to(device)\n",
    "gain_pred_lstm_model = BestGainPredictionLSTMModel(feature_input_dim, num_bs).to(device)\n",
    "\n",
    "beam_pred_lstm_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/beampred_lstm_valAcc93.01%_2025-04-29_20:55:34.pth'))\n",
    "block_pred_lstm_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead3/models/blockpred_lstm_valAcc98.87%_2025-04-26_13:08:55.pth'))\n",
    "gain_pred_lstm_model.load_state_dict(torch.load('NN_result/200_800_3Dbeam_tx(1,64)_rx(1,8)_freq2.8e+10_Np16_mode2_lookahead10/models/gainpred_lstm_valMae2.06dB_2025-04-29_20:18:49.pth'))\n",
    "\n",
    "data = preprocess_data(data_torch, pos_in_data)\n",
    "beam_pred_lstm_model.eval()\n",
    "block_pred_lstm_model.eval()\n",
    "gain_pred_lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66cce5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10000) must match the size of tensor b (146373) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     block_pred \u001b[38;5;241m=\u001b[39m block_pred_lstm_model(input_data)\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     gain_pred \u001b[38;5;241m=\u001b[39m gain_pred_lstm_model\u001b[38;5;241m.\u001b[39mpred(input_data)\n\u001b[0;32m----> 8\u001b[0m acc_block_pred \u001b[38;5;241m=\u001b[39m (\u001b[43mblock_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblock_labels\u001b[49m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      9\u001b[0m acc_beam_pred \u001b[38;5;241m=\u001b[39m (beam_pred \u001b[38;5;241m==\u001b[39m best_beam_pair_index_torch)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     10\u001b[0m mae_gain_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs((gain_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m-\u001b[39m g_opt))\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10000) must match the size of tensor b (146373) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "for input_len in range(1,look_ahead_len+1):\n",
    "    input_data = data[:10000,-input_len:,:]\n",
    "    with torch.no_grad():\n",
    "        beam_pred = beam_pred_lstm_model(input_data).argmax(dim=-1)\n",
    "        block_pred = block_pred_lstm_model(input_data).argmax(dim=-1)\n",
    "        gain_pred = gain_pred_lstm_model.pred(input_data)\n",
    "\n",
    "    acc_block_pred = (block_pred == block_labels).to(torch.float).mean()\n",
    "    acc_beam_pred = (beam_pred == best_beam_pair_index_torch).to(torch.float).mean()\n",
    "    mae_gain_pred = np.abs((gain_pred.detach().cpu().numpy() - g_opt)).mean()\n",
    "    print('Input length: ', input_len)\n",
    "    print(f'--Block prediction accuracy: {acc_block_pred.item():.4f}', )\n",
    "    print(f'--Beam prediction accuracy: {acc_beam_pred.item():.4f}', )\n",
    "    print(f'--Mean absolute error of gain prediction: {mae_gain_pred.item():.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0556d791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length:  1\n",
      "--Block prediction accuracy: 0.9791\n",
      "--Beam prediction accuracy: 0.8902\n",
      "--Mean absolute error of gain prediction: 2.6942\n",
      "Input length:  2\n",
      "--Block prediction accuracy: 0.9814\n",
      "--Beam prediction accuracy: 0.8959\n",
      "--Mean absolute error of gain prediction: 2.4839\n",
      "Input length:  3\n",
      "--Block prediction accuracy: 0.9818\n",
      "--Beam prediction accuracy: 0.8965\n",
      "--Mean absolute error of gain prediction: 2.4575\n"
     ]
    }
   ],
   "source": [
    "for input_len in range(1,look_ahead_len+1):\n",
    "    input_data = data[:,-input_len:,:]\n",
    "    with torch.no_grad():\n",
    "        beam_pred = beam_pred_lstm_model(input_data).argmax(dim=-1)\n",
    "        block_pred = block_pred_lstm_model(input_data).argmax(dim=-1)\n",
    "        gain_pred = gain_pred_lstm_model.pred(input_data)\n",
    "\n",
    "    acc_block_pred = (block_pred == block_labels).to(torch.float).mean()\n",
    "    acc_beam_pred = (beam_pred == best_beam_pair_index_torch).to(torch.float).mean()\n",
    "    mae_gain_pred = np.abs((gain_pred.detach().cpu().numpy() - g_opt)).mean()\n",
    "    print('Input length: ', input_len)\n",
    "    print(f'--Block prediction accuracy: {acc_block_pred.item():.4f}', )\n",
    "    print(f'--Beam prediction accuracy: {acc_beam_pred.item():.4f}', )\n",
    "    print(f'--Mean absolute error of gain prediction: {mae_gain_pred.item():.4f}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e638b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-66.5101, device='cuda:4'),\n",
       " tensor(-187.5919, device='cuda:4'),\n",
       " -64.07656,\n",
       " -180.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_pred.max(), gain_pred.min(), g_opt.max(), g_opt.min() #  -69.123604~-148.2894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f7406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4202566"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gain_pred and block_pred coordination\n",
    "np.abs(((gain_pred*(1-block_pred) - 180.*block_pred).detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c769b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4469101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clip gain_pred\n",
    "gain_pred_clipLB = gain_pred*(gain_pred>=-180.) - 180.*(gain_pred<-180.)\n",
    "np.abs((gain_pred_clipLB.detach().cpu().numpy() - g_opt)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c2339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90330505,  0.11447144, -0.89450836, ...,  2.6871262 ,\n",
       "       -0.29328918,  1.3418427 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gain_pred.detach().cpu().numpy()-g_opt).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fe587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gain_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist((\u001b[43mgain_pred\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m-\u001b[39mg_opt)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gain_pred' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist((gain_pred.detach().cpu().numpy()-g_opt).reshape(-1), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147903, 4]), torch.Size([147903, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_pred.shape, gain_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8561fb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147903, 4, 2]), torch.Size([147903, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_pred_lstm_model(data).shape, gain_pred_lstm_model.pred(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16eb966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_block_pred_lstm_model = block_pred_lstm_model(data)\n",
    "output_gain_pred_lstm_model = gain_pred_lstm_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef5ec6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147903, 4, 2]),\n",
       " tensor([[[  6.6171,  -4.2506],\n",
       "          [ -5.9450,   6.9206],\n",
       "          [  7.7003,  -8.2714],\n",
       "          [  5.5485,  -7.2104]],\n",
       " \n",
       "         [[ 12.5596, -11.4817],\n",
       "          [ 12.8745, -10.7068],\n",
       "          [  6.1245,  -6.6015],\n",
       "          [  1.3027,  -1.2121]],\n",
       " \n",
       "         [[ 15.5200, -13.9335],\n",
       "          [ 10.5807,  -7.5470],\n",
       "          [  2.1299,  -2.1151],\n",
       "          [-10.5589,  10.4850]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ -4.5845,   4.5399],\n",
       "          [  7.5996,  -6.2444],\n",
       "          [  7.9857,  -8.7114],\n",
       "          [  5.6381,  -6.6196]],\n",
       " \n",
       "         [[ -5.2027,   5.1565],\n",
       "          [  3.5624,  -3.5991],\n",
       "          [ 10.5413, -11.7617],\n",
       "          [  7.2885,  -8.7141]],\n",
       " \n",
       "         [[ -6.5844,   6.5532],\n",
       "          [  2.5709,  -2.5035],\n",
       "          [ 11.3501, -12.4060],\n",
       "          [  7.5030,  -9.0474]]], device='cuda:4', grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_block_pred_lstm_model.shape, output_block_pred_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89e15e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147903, 4]),\n",
       " tensor([[ 2.4703, -1.9943,  3.1746,  2.6520],\n",
       "         [ 3.0827,  2.6464,  2.6034,  0.3447],\n",
       "         [ 2.8247,  2.3920,  0.5945, -2.0076],\n",
       "         ...,\n",
       "         [-1.5296,  2.0523,  2.5126,  3.2083],\n",
       "         [-1.9940,  1.7486,  2.3294,  3.1009],\n",
       "         [-2.0009,  1.2814,  2.3381,  3.0026]], device='cuda:4',\n",
       "        grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gain_pred_lstm_model.shape, output_gain_pred_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e2102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([147903, 4]),\n",
       " tensor([[0, 1, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 1],\n",
       "         ...,\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0],\n",
       "         [1, 0, 0, 0]], device='cuda:4'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1).shape, torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e905611",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_loc = ~(block_labels == torch.nn.functional.softmax(output_block_pred_lstm_model, dim=-1).argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5641efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac3eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862c8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13397911.096200531"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "1.8e6*np.log2(1+1.24e-12 * 1e3/(10**(-174/10) * 1.8e6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
